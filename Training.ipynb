{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Helper Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(input_text, sequence_length, input_encoder):\n",
    "    x = np.zeros((len(input_text), sequence_length, len(input_encoder)), dtype=\"float32\")\n",
    "    \n",
    "    for i, inp in enumerate(input_text):\n",
    "        for t, char in enumerate(inp):\n",
    "            x[i, t, input_encoder[char]] = 1.0\n",
    "        x[i, t+1:, input_encoder[' ']] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(target_text, sequence_length, target_encoder):\n",
    "    x = np.zeros((len(target_text), sequence_length, len(target_encoder)), dtype=\"float32\")\n",
    "    y = np.zeros((len(target_text), sequence_length, len(target_encoder)), dtype=\"float32\")\n",
    "    \n",
    "    for i, inp in enumerate(target_text):\n",
    "        for t, char in enumerate(inp):\n",
    "            x[i, t, target_encoder[char]] = 1.0\n",
    "            if t > 0:\n",
    "                y[i, t - 1, target_encoder[char]] = 1.0\n",
    "        x[i, t + 1 :, target_encoder[\" \"]] = 1.0\n",
    "        y[i, t:, target_encoder[\" \"]] = 1.0\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data Preprocess*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json('data/data.json')\n",
    "input_encoder = load_json('data/input-encoder.json')\n",
    "target_encoder = load_json('data/target-encoder.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 59\n"
     ]
    }
   ],
   "source": [
    "max_inplength = max([len(txt) for txt in data['input_text']])\n",
    "max_tarlength = max([len(txt) for txt in data['target_text']])\n",
    "print(max_inplength, max_tarlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = encode_input(data['input_text'], max_inplength, input_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs, decoder_targets = encode_target(data['target_text'], max_tarlength, target_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.Input(shape=(None,len(input_encoder)), name= 'encoder_input')\n",
    "encoder = tf.keras.layers.LSTM(256, return_state=True, name = 'encoder_layer')\n",
    "encoder_output, state_h, state_c = encoder(encoder_input)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = tf.keras.Input(shape=(None, len(target_encoder)), name= 'decoder_input')\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True, name= 'decoder_layer')\n",
    "decoder_output, _, _ = decoder(decoder_input, initial_state=encoder_states)\n",
    "dense = tf.keras.layers.Dense(len(target_encoder), activation=\"softmax\", name= 'output_layer')\n",
    "\n",
    "decoder_output = dense(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model([encoder_input, decoder_input], decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None, 68)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None, 89)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer (LSTM)            [(None, 256), (None, 332800      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer (LSTM)            [(None, None, 256),  354304      decoder_input[0][0]              \n",
      "                                                                 encoder_layer[0][1]              \n",
      "                                                                 encoder_layer[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, None, 89)     22873       decoder_layer[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 709,977\n",
      "Trainable params: 709,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.1895 - accuracy: 0.7169 - val_loss: 1.4456 - val_accuracy: 0.7137\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 1.0774 - accuracy: 0.7556 - val_loss: 1.1390 - val_accuracy: 0.7142\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.9591 - accuracy: 0.7581 - val_loss: 1.1039 - val_accuracy: 0.7216\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.9170 - accuracy: 0.7617 - val_loss: 1.0506 - val_accuracy: 0.7218\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.8884 - accuracy: 0.7633 - val_loss: 1.0231 - val_accuracy: 0.7184\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.8650 - accuracy: 0.7658 - val_loss: 1.0045 - val_accuracy: 0.7286\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.8456 - accuracy: 0.7669 - val_loss: 0.9779 - val_accuracy: 0.7301\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.8271 - accuracy: 0.7682 - val_loss: 0.9650 - val_accuracy: 0.7316\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.8118 - accuracy: 0.7709 - val_loss: 0.9534 - val_accuracy: 0.7315\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.7968 - accuracy: 0.7759 - val_loss: 0.9312 - val_accuracy: 0.7400\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7829 - accuracy: 0.7819 - val_loss: 0.9188 - val_accuracy: 0.7418\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7693 - accuracy: 0.7877 - val_loss: 0.9042 - val_accuracy: 0.7509\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7566 - accuracy: 0.7927 - val_loss: 0.8906 - val_accuracy: 0.7573\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7440 - accuracy: 0.7978 - val_loss: 0.8779 - val_accuracy: 0.7602\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.7315 - accuracy: 0.8027 - val_loss: 0.8661 - val_accuracy: 0.7625\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7192 - accuracy: 0.8063 - val_loss: 0.8538 - val_accuracy: 0.7692\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.7069 - accuracy: 0.8104 - val_loss: 0.8423 - val_accuracy: 0.7685\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.6942 - accuracy: 0.8140 - val_loss: 0.8297 - val_accuracy: 0.7739\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.6820 - accuracy: 0.8179 - val_loss: 0.8145 - val_accuracy: 0.7799\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6693 - accuracy: 0.8206 - val_loss: 0.8028 - val_accuracy: 0.7825\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6569 - accuracy: 0.8242 - val_loss: 0.7905 - val_accuracy: 0.7884\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6439 - accuracy: 0.8280 - val_loss: 0.7774 - val_accuracy: 0.7885\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6316 - accuracy: 0.8307 - val_loss: 0.7630 - val_accuracy: 0.7936\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6191 - accuracy: 0.8335 - val_loss: 0.7499 - val_accuracy: 0.7976\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6077 - accuracy: 0.8359 - val_loss: 0.7373 - val_accuracy: 0.7997\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.5957 - accuracy: 0.8382 - val_loss: 0.7264 - val_accuracy: 0.8022\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.5849 - accuracy: 0.8405 - val_loss: 0.7139 - val_accuracy: 0.8041\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5745 - accuracy: 0.8427 - val_loss: 0.7035 - val_accuracy: 0.8064\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5651 - accuracy: 0.8446 - val_loss: 0.6948 - val_accuracy: 0.8084\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5554 - accuracy: 0.8469 - val_loss: 0.6853 - val_accuracy: 0.8091\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5474 - accuracy: 0.8491 - val_loss: 0.6756 - val_accuracy: 0.8125\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5402 - accuracy: 0.8504 - val_loss: 0.6695 - val_accuracy: 0.8121\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5323 - accuracy: 0.8522 - val_loss: 0.6604 - val_accuracy: 0.8151\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5262 - accuracy: 0.8535 - val_loss: 0.6580 - val_accuracy: 0.8149\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.5192 - accuracy: 0.8553 - val_loss: 0.6487 - val_accuracy: 0.8163\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5132 - accuracy: 0.8565 - val_loss: 0.6439 - val_accuracy: 0.8166\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5076 - accuracy: 0.8581 - val_loss: 0.6378 - val_accuracy: 0.8181\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.5025 - accuracy: 0.8593 - val_loss: 0.6332 - val_accuracy: 0.8209\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4977 - accuracy: 0.8597 - val_loss: 0.6275 - val_accuracy: 0.8224\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4922 - accuracy: 0.8613 - val_loss: 0.6251 - val_accuracy: 0.8222\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4877 - accuracy: 0.8625 - val_loss: 0.6194 - val_accuracy: 0.8251\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4832 - accuracy: 0.8636 - val_loss: 0.6162 - val_accuracy: 0.8226\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4793 - accuracy: 0.8645 - val_loss: 0.6126 - val_accuracy: 0.8246\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4747 - accuracy: 0.8653 - val_loss: 0.6079 - val_accuracy: 0.8266\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.4712 - accuracy: 0.8662 - val_loss: 0.6042 - val_accuracy: 0.8267\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4672 - accuracy: 0.8673 - val_loss: 0.6018 - val_accuracy: 0.8271\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4640 - accuracy: 0.8677 - val_loss: 0.5974 - val_accuracy: 0.8274\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4598 - accuracy: 0.8690 - val_loss: 0.5962 - val_accuracy: 0.8293\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4569 - accuracy: 0.8695 - val_loss: 0.5931 - val_accuracy: 0.8288\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.4531 - accuracy: 0.8704 - val_loss: 0.5893 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f381060cc90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    decoder_targets,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Eng2Fre.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
